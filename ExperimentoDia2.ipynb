{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando para algoritmo: <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\n",
      "Melhor seleção de hyperparâmetros:\n",
      "\n",
      "{'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "Scores (% de acertos) nos folds de validação:\n",
      "\n",
      "0.810 (+/-0.152) for {'n_neighbors': 2, 'p': 1, 'weights': 'uniform'}\n",
      "0.730 (+/-0.182) for {'n_neighbors': 2, 'p': 1, 'weights': 'distance'}\n",
      "0.815 (+/-0.154) for {'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}\n",
      "0.737 (+/-0.179) for {'n_neighbors': 2, 'p': 2, 'weights': 'distance'}\n",
      "0.781 (+/-0.174) for {'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "0.778 (+/-0.175) for {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "0.792 (+/-0.172) for {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "0.789 (+/-0.172) for {'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n",
      "0.804 (+/-0.165) for {'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
      "0.801 (+/-0.168) for {'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "0.811 (+/-0.166) for {'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "0.808 (+/-0.168) for {'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
      "0.828 (+/-0.144) for {'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
      "0.819 (+/-0.157) for {'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
      "0.829 (+/-0.145) for {'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}\n",
      "0.822 (+/-0.160) for {'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "Resultado detalhado para o melhor modelo:\n",
      "\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RFECV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1ae7f7ed9aea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nResultado detalhado para o melhor modelo:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RFECV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # primeiro importamos a biblioteca para visualização\n",
    "import numpy as np  # importamos também a biblioteca NumPy que irá nos fornecer diversos métodos para trabalhar com arrays\n",
    "import seaborn as sns\n",
    "\n",
    "#funcao auxiliar de conversao\n",
    "def converte_categorias(df):\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    # job\n",
    "    df.job = pd.Categorical(df.job)\n",
    "    df['job'] = df.job.cat.codes\n",
    "    # marital\n",
    "    df.marital = pd.Categorical(df.marital)\n",
    "    df['marital'] = df.marital.cat.codes\n",
    "    # education\n",
    "    df.education = pd.Categorical(df.education)\n",
    "    df['education'] = df.education.cat.codes\n",
    "    # default\n",
    "    df.default = pd.Categorical(df.default)\n",
    "    df['default'] = df.default.cat.codes\n",
    "    # housing\n",
    "    df.housing = pd.Categorical(df.housing)\n",
    "    df['housing'] = df.housing.cat.codes\n",
    "    # loan\n",
    "    df.loan = pd.Categorical(df.loan)\n",
    "    df['loan'] = df.loan.cat.codes\n",
    "    # contact\n",
    "    df.contact = pd.Categorical(df.contact)\n",
    "    df['contact'] = df.contact.cat.codes\n",
    "    # month\n",
    "    df.month = pd.Categorical(df.month)\n",
    "    df['month'] = df.month.cat.codes\n",
    "    # outcome\n",
    "    df.poutcome = pd.Categorical(df.poutcome)\n",
    "    df['poutcome'] = df.poutcome.cat.codes\n",
    "    return df\n",
    "\n",
    "#dataset\n",
    "trainset = pd.read_csv(\"data/trainset.csv\")\n",
    "testset = pd.read_csv(\"data/testset.csv\")\n",
    "\n",
    "X_train = trainset.loc[:, trainset.columns != \"y\"]\n",
    "y_train = trainset.loc[:, trainset.columns == \"y\"]\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "\n",
    "X_test = testset.loc[:, testset.columns != \"y\"]\n",
    "y_test = testset.loc[:, testset.columns == \"y\"]\n",
    "y_test = y_test.values.ravel()\n",
    "#trainset\n",
    "\n",
    "#visualização está ok\n",
    "#sns.pairplot(trainset, hue=\"y\")  # o parametro 'hue' diz qual coluna contém o alvo para distribuir as cores\n",
    "\n",
    "#convertendo os dados para numérico\n",
    "X_train = converte_categorias(X_train)\n",
    "X_test = converte_categorias(X_test)\n",
    "#X_train\n",
    "\n",
    "\n",
    "\n",
    "#importando os arquivos necessários\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "folds = 3  # precisa ser maior que 2 - Interessante entre 5 e 10\n",
    "\n",
    "# aqui nós criamos um objeto dicionário com o nome do hyperparâmetro e os possíveis valores que ele pode assumir\n",
    "# os hyperparâmetros são específicos para cada algoritmo! Note como neste caso nós chamamos a classe do algoritmo\n",
    "# sem passarmos os hyperparâmetros default\n",
    "\n",
    "#KNeighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    \"n_neighbors\": [2, 3, 5, 10],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"p\": [1, 2]\n",
    "}\n",
    "\n",
    "#MLPerceptron\n",
    "pcptron = MLPClassifier()\n",
    "pcptron_params = {\n",
    "    \"hidden_layer_sizes\": [1,2],    \n",
    "    \"max_iter\": [50,100,200]    \n",
    "}\n",
    "\n",
    "#RandomForest\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {\n",
    "    \"n_estimators\": [5,10],\n",
    "    \"criterion\": [\"entropy\"],\n",
    "    \"max_features\": [\"auto\",\"sqrt\"]\n",
    "}\n",
    "\n",
    "\n",
    "# O scikit learn e uma biblioteca bastante flexível. Com poucas linhas de código, podemos executar o mesmo experimento\n",
    "# para diversos algoritmos: basta criar uma lista contendo os algoritmos e uma segunda lista contendo os \n",
    "# dicionários de hyperparâmetros. Detalhe: a ordem das listas é importante!\n",
    "classifiers = [knn,rf]\n",
    "grids = [knn_params,rf_params]\n",
    "\n",
    "# gera uma lista de tuplas entre classifiers e grids para que cada um fique na\n",
    "# posição correta [(class.1, parms.1), (class.2, params.2), ...]\n",
    "grid_params = zip(classifiers, grids)\n",
    "\n",
    "# aqui fazemos a busca - neste caso a busca é por força bruta, ou seja, vai\n",
    "# testar todas as combinações que incluirmos no dicionário de parâmetros - há\n",
    "# também a opção de se buscar randomicamente, mas precisariamos definir\n",
    "# distribuições ao invés de parâmetros e os resultados são parecidos.\n",
    "# a busca vai ser feita pelo ``score'' que definirmos\n",
    "\n",
    "\n",
    "\n",
    "for _, (classifier, params) in enumerate(grid_params):\n",
    "\n",
    "    print(\"Buscando para algoritmo: {0}\\n\".format(classifier.__class__))\n",
    "    \n",
    "    \n",
    "    clf = GridSearchCV(estimator=classifier,  # algoritmo em teste\n",
    "                               param_grid=params,  # parâmetros de busca\n",
    "                               cv=folds,  # objeto que vai gerar as divisões\n",
    "                               n_jobs=-1, #processamento\n",
    "                               scoring='accuracy')  # score que será utilizado\n",
    "        \n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "\n",
    "    # aqui nós imprimimos o resultado - o método report vai imprimir as ``top''\n",
    "    # melhores combinações encontrada na busca. Os parâmetros impressos\n",
    "    # são aqueles que teríamos que usar para gerar o classificador de forma isolada\n",
    "    print(\"Melhor seleção de hyperparâmetros:\\n\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\nScores (% de acertos) nos folds de validação:\\n\")\n",
    "    means = clf.cv_results_['mean_test_score'] #clf\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"{:.3f} (+/-{:.3f}) for {}\".format(mean, std * 2, params))\n",
    "\n",
    "    print(\"\\nResultado detalhado para o melhor modelo:\\n\")\n",
    "    y_true, y_pred = y_test, rfecv.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
